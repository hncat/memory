# 局部性原则
```
时间局部性: 某个数据项在被访问之后可能很快被再次访问的特性
空间局部性: 某个数据项在被访问之后，与其地址相近的数据项可能很快被访问的特性
```
# DRAM & SRAM
```
RAM：随机访问存储器，其访问任意位置的速度基本一致
DRAM：动态随机访问存储器      ----->       内存
SRAM：静态随机访问存储器      ----->       高速缓存
```
# DMA
```
DMA：直接内存访问
它允许不同速度的硬件设备来沟通，而不需要依于中央处理器的大量中断负载。否则，中央处理器需要从来源把每一片段的资料复制到寄存器，然后把它们再次写回到新的地方。在这个时间中，中央处理器对于其他的工作来说就无法使用。
```
# 存储器的层次结构图
```
呈金字塔型分布，由上到下依次为:
                        /\
                       /  \
                      / 寄 \
                     / 存器 \
                    /————————\
                   /    L1    \
                  /   高速缓存  \
                 /    (SRAM)    \
                /————————————————\
               /        L2        \
              /       高速缓存      \
             /        (SRAM)        \
            /————————————————————————\
           /            L3            \
          /           高速缓存          \
         /            (SRAM)            \
        /————————————————————————————————\
       /             主存(DRAM)           \
      /————————————————————————————————————\
     /          本地二级存储(本地磁盘)        \
    /————————————————————————————————————————\
   /                远程二级存储               \
  /          (分布式存储系统, web服务器)         \
 /______________________________________________\
造价和速度由上到下依次减小，容量由上到下依次增大。
高速缓存(cache)：用于保存经常被访问的内存从而提升计算机的整体性能，遵循局部性原则。
```
# 逻辑地址(虚拟地址)与实地址(物理地址)
```
编译时可确定的内存地址称为静态绑定(static bind)
运行时可确定的内存地址称为动态绑定(dynamic bind)
```
# MMU(内存管理单元)
```
CPU执行时始终获取的是虚拟地址，操作内存时由虚拟地址转换成物理地址的操作交由MMU管理
```
## 连续内存分配
```
每个进程按顺序依次分配内存，进程执行结束后内存回收。
缺点：容易产生内存碎片，如下图process10 和 process2之间的内存空间
解决：压缩（需要耗费大量I/O）[x x x x]-------->[xxxx   ]
```
<image src="连续内存分配.png">

## 段式分配
```
s：段号
d：段内偏移量
limit：段长度
base：段基地址
同样会产生内存碎片
```
<image src="段式内存分配.png">

## 页式内存分配
```
p：页号(页表内的偏移量)
d：帧偏移量
```
<image src="页内存分配.png">

## TLB
```
相当于页表的缓冲
```
<image src="TLB.png">

# 虚拟内存
## 比物理内存大的虚拟内存
<image src="比物理内存大的虚拟内存.png">

```
如上图所示有如下几个概念：
虚拟内存：既程序的逻辑地址
物理地址：内存的真实物理地址
(内存映射)memory map：虚拟内存地址映射到物理内存地址的过程
1.CPU能直接访问的存储设备只能是内存而不能是磁盘，所以当程序运行时执行内存访问操作时，CPU通过虚拟内存地址映射到内存对应的物理内存地址进行操作。
2.程序的虚拟内存是通过分页(page)进行管理的，而物理内存把这种分页的块称为帧(frame)。在程序加载进内存时，物理内存的每一帧分配给虚拟内存的每一页。
3.物理内存不足时将程序后续的虚拟内存通过分页的方式写入磁盘。
4.CPU访问虚拟内存时，如果程序的虚拟内存通过内存映射，内存地址刚好位于内存中则可直接访问。
5.CPU访问虚拟内存时，如果程序的虚拟内存通过内存映射，内存地址无法在内存中找到则会触发缺页中断程序需要在磁盘中找到对应的虚拟内存页(page)，然后在内存中找到一块可用的帧(free jframe)接着将虚拟内存页(page)写入内存中。如果虚拟内存不够用则和内存中的某一块帧(frame)进行替换。最后才能供CPU继续访问。
```
## 换页
<image src="换页.png">
<image src="缺页中断的处理流程.png">

# 大容量存储系统
## 磁盘
```
磁盘巡道时间\磁盘旋转时间、磁盘传输时间
```
<image src="磁盘.png">

## 固态磁盘
```
并行、闪存、有使用寿命
```

# 缓存(cache)
```
缓存命中

缓存不命中
冷不命中(强制性不命中)：当一个缓存为空时就会发生，通常这种不命中是短暂的。
冲突不命中：当不同的块被访问时因为缓存位置是相同的就会重复的发生缓存替换。
容量不命中：当程序内存块大于缓存块时，操作内存时需要将内存块加入缓存而发生不命中。比如一个嵌套的循环可能会重复访问同一个数组的元素。这个快的集合被称为工作集。当工作集的大小超过缓存的大小时，缓存会经历容量不命中。
```
## 直接映射高速缓存
```
容易出现冲突不命中，原因是直接缓存映射时每一组内存缓存中只有一行内存缓存行
例如：
E = 1 (行)
S = 4 (组)
b = 2 (字节块)

对于四位的地址: 0(0000) ~ 15(1111)
给出如下表：

地址  |  标记位 | 组索引 | 偏移位 | 对应缓存块编号
        （t=1）  （s=2）  （b=1）
0000  |   0    |   00   |  0    | 0
0001  |   0    |   00   |  1    | 0
0010  |   0    |   01   |  0    | 1
0011  |   0    |   01   |  1    | 1
0100  |   0    |   10   |  0    | 2
0101  |   0    |   10   |  1    | 2
0110  |   0    |   11   |  0    | 3
0111  |   0    |   11   |  1    | 3
1000  |   1    |   00   |  0    | 0
1001  |   1    |   00   |  1    | 0
1010  |   1    |   01   |  0    | 1
1011  |   1    |   01   |  1    | 1
1100  |   1    |   10   |  0    | 2
1101  |   1    |   10   |  1    | 2
1110  |   1    |   11   |  0    | 3
1111  |   1    |   11   |  1    | 3
如上表所示：当地址为0000和地址为1000时虽然组索引相同但是对应的tag(标记位不等)此时造成冲突不命中。
```
<image src="直接映射高速缓存.png">

## 组相联高速缓存
```
相对于直接映射高速缓存而言，组相联高速缓存放宽了冲突不命中。因为每组高速缓存中放置了多行高速缓存行。但是它的行匹配将会更复杂，因为它要匹配多行中的有效位和标记位。
```
<image src="组相联高速缓存.png">

## 全相联高速缓存
```
因为高速缓存电路必须并行的搜索许多相匹配的标记，构造一个又大又快的相联高速缓存很困难，而且非常昂贵。因此全相联高速缓存只适合做小的高速缓存，如TLB。
```
<image src="全相联高速缓存.png">